{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "CACHE_LEFT_SLOPE = 0\n",
    "CACHE_RIGHT_SLOPE = 0\n",
    "CACHE_LEFT = [0, 0, 0]\n",
    "CACHE_RIGHT = [0, 0, 0]\n",
    "\n",
    "def reset_globals():\n",
    "    \"\"\"\n",
    "    Clear your globals before using new outputs\n",
    "    \"\"\"\n",
    "    print(\"RESETING GLOBAL VALUES\")\n",
    "    global CACHE_LEFT_SLOPE\n",
    "    global CACHE_RIGHT_SLOPE\n",
    "    global CACHE_LEFT\n",
    "    global CACHE_RIGHT\n",
    "    CACHE_LEFT_SLOPE = 0\n",
    "    CACHE_RIGHT_SLOPE = 0\n",
    "    CACHE_LEFT = [0, 0, 0]\n",
    "    CACHE_RIGHT = [0, 0, 0]\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=16):\n",
    "    \"\"\"\n",
    "    This function draws `lines` with `color` and `thickness`.\n",
    "    It will look at the hough lines, filter them and then assign them to left or right line.\n",
    "    I also use global variables to smooth the jitter from frame to frame.\n",
    "    \"\"\"\n",
    "    global CACHE_LEFT_SLOPE\n",
    "    global CACHE_RIGHT_SLOPE\n",
    "    global CACHE_LEFT\n",
    "    global CACHE_RIGHT\n",
    "\n",
    "    # DECLARE VARIABLES\n",
    "    cache_weight = 0.9\n",
    "\n",
    "    right_ys = []\n",
    "    right_xs = []\n",
    "    right_slopes = []\n",
    "\n",
    "    left_ys = []\n",
    "    left_xs = []\n",
    "    left_slopes = []\n",
    "\n",
    "    midpoint = img.shape[1] / 2\n",
    "    bottom_of_image = img.shape[0]\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope, yint = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            # Filter lines using slope and x position\n",
    "            if .35 < np.absolute(slope) <= .85:\n",
    "                if slope > 0 and x1 > midpoint and x2 > midpoint:\n",
    "                    right_ys.append(y1)\n",
    "                    right_ys.append(y2)\n",
    "                    right_xs.append(x1)\n",
    "                    right_xs.append(x2)\n",
    "                    right_slopes.append(slope)\n",
    "                elif slope < 0 and x1 < midpoint and x2 < midpoint:\n",
    "                    left_ys.append(y1)\n",
    "                    left_ys.append(y2)\n",
    "                    left_xs.append(x1)\n",
    "                    left_xs.append(x2)\n",
    "                    left_slopes.append(slope)\n",
    "\n",
    "    # DRAW RIGHT LANE LINE\n",
    "    if right_ys:\n",
    "        right_index = right_ys.index(min(right_ys))\n",
    "        right_x1 = right_xs[right_index]\n",
    "        right_y1 = right_ys[right_index]\n",
    "        right_slope = np.median(right_slopes)\n",
    "        if CACHE_RIGHT_SLOPE != 0:\n",
    "            right_slope = right_slope + (CACHE_RIGHT_SLOPE - right_slope) * cache_weight\n",
    "\n",
    "        right_x2 = int(right_x1 + (bottom_of_image - right_y1) / right_slope)\n",
    "\n",
    "        if CACHE_RIGHT_SLOPE != 0:\n",
    "            right_x1 = int(right_x1 + (CACHE_RIGHT[0] - right_x1) * cache_weight)\n",
    "            right_y1 = int(right_y1 + (CACHE_RIGHT[1] - right_y1) * cache_weight)\n",
    "            right_x2 = int(right_x2 + (CACHE_RIGHT[2] - right_x2) * cache_weight)\n",
    "\n",
    "        CACHE_RIGHT_SLOPE = right_slope\n",
    "        CACHE_RIGHT = [right_x1, right_y1, right_x2]\n",
    "\n",
    "        cv2.line(img, (right_x1, right_y1), (right_x2, bottom_of_image), color, thickness)\n",
    "\n",
    "    # DRAW LEFT LANE LINE\n",
    "    if left_ys:\n",
    "        left_index = left_ys.index(min(left_ys))\n",
    "        left_x1 = left_xs[left_index]\n",
    "        left_y1 = left_ys[left_index]\n",
    "        left_slope = np.median(left_slopes)\n",
    "        if CACHE_LEFT_SLOPE != 0:\n",
    "            left_slope = left_slope + (CACHE_LEFT_SLOPE - left_slope) * cache_weight\n",
    "\n",
    "        left_x2 = int(left_x1 + (bottom_of_image - left_y1) / left_slope)\n",
    "\n",
    "        if CACHE_LEFT_SLOPE != 0:\n",
    "            left_x1 = int(left_x1 + (CACHE_LEFT[0] - left_x1) * cache_weight)\n",
    "            left_y1 = int(left_y1 + (CACHE_LEFT[1] - left_y1) * cache_weight)\n",
    "            left_x2 = int(left_x2 + (CACHE_LEFT[2] - left_x2) * cache_weight)\n",
    "\n",
    "        CACHE_LEFT_SLOPE = left_slope\n",
    "        CACHE_LEFT = [left_x1, left_y1, left_x2]\n",
    "\n",
    "        cv2.line(img, (left_x1, left_y1), (left_x2, bottom_of_image), color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "            #cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def process_image(image):\n",
    "    # PARAMETERS\n",
    "    imshape = image.shape\n",
    "    kernel_size = 3\n",
    "    sigma_x = 0\n",
    "    low_canny_threshold = 25\n",
    "    high_canny_threshold = low_canny_threshold * 3\n",
    "    vertices = np.array([[(0,imshape[0]), (9*imshape[1]/20, 11*imshape[0]/18), (11*imshape[1]/20, 11*imshape[0]/18), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    ignore_mask_color = 255\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    hough_threshold = 10\n",
    "    min_line_len = 30\n",
    "    max_line_gap = 60\n",
    "    α = 0.8\n",
    "    β = 1.\n",
    "    λ = 0.\n",
    "    \n",
    "    #def process_image(image):\n",
    "    # GRAYSCALE\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # GAUSSIAN BLUR\n",
    "    blur = cv2.GaussianBlur(gray, (kernel_size, kernel_size), sigma_x)\n",
    "\n",
    "    # CANNY EDGES\n",
    "    edges = cv2.Canny(blur, low_canny_threshold, high_canny_threshold)\n",
    "\n",
    "    # REGION MASK\n",
    "    mask = np.zeros_like(edges)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "    # HOUGH TRANSFORM\n",
    "    lines = cv2.HoughLinesP(masked, rho, theta, hough_threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    hough_image = np.zeros((*masked.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(hough_image, lines)\n",
    "\n",
    "    # WEIGHTED IMAGE\n",
    "    processed = cv2.addWeighted(image, α, hough_image, β, λ)\n",
    "\n",
    "    return processed\n",
    "    #plt.imshow(final_image)\n",
    "    #plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESETING GLOBAL VALUES\n",
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 221/222 [00:05<00:00, 43.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "Wall time: 5.86 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_globals()\n",
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "#Play video inline\n",
    "\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    #image = mpimg.imread('test_images/whiteCarLaneSwitch.jpg')\n",
    "    #plt.imshow(process_image(image))\n",
    "    #plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
